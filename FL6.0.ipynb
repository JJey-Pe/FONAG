{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a56def79-04d9-449e-9374-3c7c637a94d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import ttk\n",
    "import pandas as pd\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "rangos = pd.DataFrame(index=range(2), columns=range(1))\n",
    "\n",
    "def CDG(df, a, b, c, d):\n",
    "\n",
    "    # Diccionario de DF por cada estaciÃ³n\n",
    "    Estaciones = {}\n",
    "    percent = {}\n",
    "    # Percentilies deseados\n",
    "    Prob = [a, b, c]\n",
    "    for columna in df.columns:\n",
    "        # Crear un DataFrame para cada estaciÃ³n y ordenarlo\n",
    "        est = df[[columna]].dropna().sort_values(by=columna, ascending=False).reset_index(drop=True)\n",
    "        est = est.iloc[:-3,:]\n",
    "        est = est.iloc[1:,:]\n",
    "        est['Probabilidad'] = 100*(est.index + 1) / (len(est) + 1)\n",
    "        Estaciones[columna] = est\n",
    "            \n",
    "        i = 0\n",
    "        P = pd.DataFrame(np.zeros((len(Prob), 2)), columns=['Nivel', 'Probabilidad'])\n",
    "\n",
    "        for p in Prob:\n",
    "            idx = (est.iloc[:, 1] - p).abs().idxmin()\n",
    "            P.at[i, 'Nivel'] = float(\"{:.2f}\".format(est.iloc[idx, 0]))\n",
    "            P.at[i, 'Probabilidad'] = float(\"{:.2f}\".format(est.iloc[idx, 1]))\n",
    "            i = i + 1\n",
    "        percent[columna] = P.copy()\n",
    "    rangos.iloc[d,0] = str((a, b, c))\n",
    "    Percentiles.append(percent)\n",
    "    \n",
    "    return Percentiles, rangos\n",
    "\n",
    "def LeerArchivos(a):\n",
    "    # Crear una ventana raíz\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Ocultar la ventana principal\n",
    "    # Hacer que la ventana esté siempre en el frente\n",
    "    root.attributes('-topmost', True)\n",
    "    # Abrir un cuadro de diálogo para seleccionar un archivo CSV\n",
    "    file_path = filedialog.askopenfilename(\n",
    "        title=f\"Selecciona un archivo CSV de {a}\",\n",
    "        filetypes=((\"CSV files\", \"*.csv\"), (\"Todos los archivos\", \"*.*\")))\n",
    "    # Mostrar la ruta del archivo seleccionado\n",
    "    print(f\"Archivo seleccionado: {file_path}\")\n",
    "\n",
    "    # Cerrar la ventana raíz\n",
    "    root.destroy()\n",
    "        \n",
    "    if file_path:  # Verificar si se seleccionó un archivo\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, index_col=None)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al leer el archivo: {e}\")\n",
    "    else:\n",
    "        print(\"No se seleccionó ningún archivo.\")\n",
    "        \n",
    "    df.iloc[:, 0] = pd.to_datetime(df.iloc[:,0])\n",
    "    df = df.set_index(df.columns[0])\n",
    "        \n",
    "    return df\n",
    "\n",
    "def ElegirEstacion(Data, a):\n",
    "    \n",
    "    def Seleccion():\n",
    "        columna_seleccionada = columna_var.get()\n",
    "        print(f\"Has seleccionado la estación: {columna_seleccionada}\")\n",
    "        root.destroy()  # Cierra la ventana\n",
    "    \n",
    "    # Crear la ventana principal de Tkinter\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Selecciona una estación de {a}\")\n",
    "    # Hacer que la ventana esté siempre en el frente\n",
    "    root.attributes('-topmost', True)\n",
    "    # Variable para almacenar la selección\n",
    "    columna_var = tk.StringVar()\n",
    "    columna_var.set(Data.columns[0])  # Valor inicial en el OptionMenu\n",
    "    dropdown = ttk.OptionMenu(root, columna_var, *Data.columns)\n",
    "    dropdown.pack(pady=10)\n",
    "    # Botón para confirmar la selección\n",
    "    boton = tk.Button(root, text=\"Seleccionar\", command = Seleccion)\n",
    "    boton.pack(pady=20)\n",
    "    # Iniciar la ventana\n",
    "    root.mainloop()\n",
    "    columna_seleccionada = columna_var.get()\n",
    "    \n",
    "    return columna_seleccionada\n",
    "\n",
    "def ANN():\n",
    "    # Escalar los datos entre 0 y 1\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    data_scaled = scaler.fit_transform(pd.DataFrame(DatosPrec[EstP]))\n",
    "    \n",
    "    # Dividir los datos en conjunto de entrenamiento y prueba (80% - 20%)\n",
    "    train_size = int(len(data_scaled) * 0.8)\n",
    "    train, test = data_scaled[:train_size], data_scaled[train_size:]\n",
    "    \n",
    "    # Crear una función para transformar los datos en formato adecuado para LSTM (multivariables)\n",
    "    def create_dataset(data, look_back=90, forecast_horizon=dias_futuros-1):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - look_back - forecast_horizon):\n",
    "            X.append(data[i:(i + look_back), :])  # Tomar todas las características\n",
    "            y.append(data[(i + look_back):(i + look_back + forecast_horizon), 0])  # Predecir la primera variable\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    # Usamos 90 días para predecir los próximos 7 días\n",
    "    look_back = 90\n",
    "    forecast_horizon = dias_futuros-1\n",
    "    X_train, y_train = create_dataset(train, look_back, forecast_horizon)\n",
    "    X_test, y_test = create_dataset(test, look_back, forecast_horizon)\n",
    "    \n",
    "    # Reshape para que el modelo LSTM lo entienda (samples, time steps, features)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "    \n",
    "    # Parámetros de entrenamiento\n",
    "    epochs = 10\n",
    "    batch_size = 10\n",
    "    \n",
    "    # Crear el modelo LSTM\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=(look_back, 1)))  # Hay 'num_vars' variables de entrada\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(forecast_horizon))  # Predecir los próximos 6 días\n",
    "    \n",
    "    # Compilar el modelo\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=2)\n",
    "    \n",
    "    # Realizar el pronóstico\n",
    "    test_predict = model.predict(X_test)\n",
    "    \n",
    "    # Invertir el escalado para las predicciones y los valores reales\n",
    "    test_predict_unscaled = []\n",
    "    y_test_unscaled = []\n",
    "    \n",
    "    for i in range(test_predict.shape[0]):\n",
    "        temp_predict = scaler.inverse_transform(np.concatenate([test_predict[i].reshape(-1, 1), np.tile(X_test[i, -1, 1:], (forecast_horizon, 1))], axis=1))[:, 0]\n",
    "        temp_y_test = scaler.inverse_transform(np.concatenate([y_test[i].reshape(-1, 1), np.tile(X_test[i, -1, 1:], (forecast_horizon, 1))], axis=1))[:, 0]\n",
    "        test_predict_unscaled.append(temp_predict)\n",
    "        y_test_unscaled.append(temp_y_test)\n",
    "    \n",
    "    test_predict_unscaled = np.array(test_predict_unscaled)\n",
    "    y_test_unscaled = np.array(y_test_unscaled)\n",
    "\n",
    "    return test_predict_unscaled\n",
    "\n",
    "def LogicaDifusa(P, N):\n",
    "    \n",
    "    # Antecedentes (precipitaciónn y nivel) y consecuente (Nivel o caudal)\n",
    "    PrecP = ctrl.Antecedent([P[EstP].min(), Percentiles[1][EstP].iloc[2, 0], Percentiles[1][EstP].iloc[1, 0], Percentiles[1][EstP].iloc[0, 0], P[EstP].max()], 'Precipitación Pasada')\n",
    "    PrecP2 = ctrl.Antecedent([P[EstP].min(), Percentiles[1][EstP].iloc[2, 0], Percentiles[1][EstP].iloc[1, 0], Percentiles[1][EstP].iloc[0, 0], P[EstP].max()], 'Precipitación Pasada2')\n",
    "    NivP = ctrl.Antecedent([N[EstN].min(), Percentiles[0][EstN].iloc[2,0], Percentiles[0][EstN].iloc[1,0], Percentiles[0][EstN].iloc[0, 0], N[EstN].max()], 'Nivel Pasado')\n",
    "    Niv = ctrl.Consequent([N[EstN].min(), Percentiles[0][EstN].iloc[2,0], Percentiles[0][EstN].iloc[1,0], Percentiles[0][EstN].iloc[0, 0], N[EstN].max()], 'Nivel')\n",
    "    \n",
    "    # Definición de membresí­as\n",
    "    PrecP['Bajo'] = fuzz.trimf(PrecP.universe, [P[EstP].min(), P[EstP].min(), Percentiles[1][EstP].iloc[2, 0]])\n",
    "    PrecP['Medio-Bajo'] = fuzz.trimf(PrecP.universe, [P[EstP].min(), Percentiles[1][EstP].iloc[2, 0], Percentiles[1][EstP].iloc[1, 0]])\n",
    "    PrecP['Medio'] = fuzz.trimf(PrecP.universe, [Percentiles[1][EstP].iloc[2, 0], Percentiles[1][EstP].iloc[1, 0], Percentiles[1][EstP].iloc[0, 0]])\n",
    "    PrecP['Alto'] = fuzz.trapmf(PrecP.universe, [Percentiles[1][EstP].iloc[1, 0], Percentiles[1][EstP].iloc[0, 0], P[EstP].max(), P[EstP].max()])\n",
    "\n",
    "    PrecP2['Bajo'] = fuzz.trimf(PrecP.universe, [P[EstP].min(), P[EstP].min(), Percentiles[1][EstP].iloc[2, 0]])\n",
    "    PrecP2['Medio-Bajo'] = fuzz.trimf(PrecP.universe, [P[EstP].min(), Percentiles[1][EstP].iloc[2, 0], Percentiles[1][EstP].iloc[1, 0]])\n",
    "    PrecP2['Medio'] = fuzz.trimf(PrecP.universe, [Percentiles[1][EstP].iloc[2, 0], Percentiles[1][EstP].iloc[1, 0], Percentiles[1][EstP].iloc[0, 0]])\n",
    "    PrecP2['Alto'] = fuzz.trapmf(PrecP.universe, [Percentiles[1][EstP].iloc[1, 0], Percentiles[1][EstP].iloc[0, 0], P[EstP].max(), P[EstP].max()])\n",
    "\n",
    "    NivP['Bajo'] = fuzz.trimf(Niv.universe, [N[EstN].min(), N[EstN].min(), Percentiles[0][EstN].iloc[2, 0]])\n",
    "    NivP['Medio-Bajo'] = fuzz.trimf(Niv.universe, [N[EstN].min(), Percentiles[0][EstN].iloc[2, 0], Percentiles[0][EstN].iloc[1, 0]])\n",
    "    NivP['Medio'] = fuzz.trimf(Niv.universe, [Percentiles[0][EstN].iloc[2, 0], Percentiles[0][EstN].iloc[1, 0], Percentiles[0][EstN].iloc[0, 0]])\n",
    "    NivP['Alto'] = fuzz.trapmf(Niv.universe, [Percentiles[0][EstN].iloc[1, 0], Percentiles[0][EstN].iloc[0, 0], N[EstN].max(), N[EstN].max()])\n",
    "    \n",
    "    Niv['Bajo (90-100%)'] = fuzz.trimf(Niv.universe, [N[EstN].min(), N[EstN].min(), Percentiles[0][EstN].iloc[2, 0]])\n",
    "    Niv['Medio-Bajo (50-90%)'] = fuzz.trimf(Niv.universe, [N[EstN].min(), Percentiles[0][EstN].iloc[2, 0], Percentiles[0][EstN].iloc[1, 0]])\n",
    "    Niv['Medio (10-50%)'] = fuzz.trimf(Niv.universe, [Percentiles[0][EstN].iloc[2, 0], Percentiles[0][EstN].iloc[1, 0], Percentiles[0][EstN].iloc[0, 0]])\n",
    "    Niv['Alto (0-10%)'] = fuzz.trapmf(Niv.universe, [Percentiles[0][EstN].iloc[1, 0], Percentiles[0][EstN].iloc[0, 0], N[EstN].max(), N[EstN].max()])\n",
    "\n",
    "    # REGLAS\n",
    "    B = ctrl.Rule(PrecP['Bajo'], Niv['Bajo (90-100%)'])\n",
    "    MB = ctrl.Rule(PrecP['Medio-Bajo'], Niv['Medio-Bajo (50-90%)'])\n",
    "    M = ctrl.Rule(PrecP['Medio'], Niv['Medio (10-50%)'])\n",
    "    A = ctrl.Rule(PrecP['Alto'], Niv['Alto (0-10%)'])\n",
    "\n",
    "    B2 = ctrl.Rule(PrecP2['Bajo'], Niv['Bajo (90-100%)'])\n",
    "    MB2 = ctrl.Rule(PrecP2['Medio-Bajo'], Niv['Medio-Bajo (50-90%)'])\n",
    "    M2 = ctrl.Rule(PrecP2['Medio'], Niv['Medio (10-50%)'])\n",
    "    A2 = ctrl.Rule(PrecP2['Alto'], Niv['Alto (0-10%)'])\n",
    "\n",
    "    Bn = ctrl.Rule(NivP['Bajo'], Niv['Bajo (90-100%)'])\n",
    "    MBn = ctrl.Rule(NivP['Medio-Bajo'], Niv['Medio-Bajo (50-90%)'])\n",
    "    Mn = ctrl.Rule(NivP['Medio'], Niv['Medio (10-50%)'])\n",
    "    An = ctrl.Rule(NivP['Alto'], Niv['Alto (0-10%)'])\n",
    "    \n",
    "    Pronosticos = pd.DataFrame(np.nan, index=DatosPrec[EstP].iloc[-dias_pasados:].index, columns=[f\"Día {i+1}\" for i in range(dias_futuros)], dtype=float)\n",
    "    N_Variables = int(input(\"¿Con qué variables desea trabajar?:\\n1. Precipitación t-1\\n2. Nivel t-1\\n3. Precipitación t-1, t-2\\n4. Precipitación t-1 y nivel t-1\\n5. Precipitación t-1, t-2 y nivel t-1\\n\"))\n",
    "    \n",
    "    if N_Variables == 1:\n",
    "        #Parametros para pdf\n",
    "        text = \"1Variable_P(t-1)\"\n",
    "        estaciones = f'{EstP}'\n",
    "        REGLAS = \"precipitación t-1\"\n",
    "        # Parámetros para pronóstico\n",
    "        reglas = [B, MB, M, A]\n",
    "        def FL(i, dia):\n",
    "            Nivel.input['Precipitación Pasada'] = Prec_In.iloc[i, dia]\n",
    "            Nivel.compute()\n",
    "            Pronosticos.iloc[i, dia] = float(Nivel.output['Nivel'])\n",
    "            DATOS.iloc[i,0] = Prec_In.iloc[i, dia]\n",
    "            DATOS.iloc[i,3] = float(Nivel.output['Nivel'])\n",
    "        \n",
    "    if N_Variables == 2:\n",
    "        #Parametros para pdf\n",
    "        text = \"1Variable_N(t-1)\"\n",
    "        estaciones = f'{EstN}'\n",
    "        REGLAS = \"nivel t-1\"\n",
    "        # Parámetros para pronóstico\n",
    "        reglas = [Bn, MBn, Mn, An]\n",
    "        def FL(i, dia):\n",
    "            Nivel.input['Nivel Pasado'] = Nivel_In.iloc[i, dia]\n",
    "            Nivel.compute()\n",
    "            Pronosticos.iloc[i, dia] = float(Nivel.output['Nivel'])\n",
    "            Nivel_In.iloc[i, dia + 1] = float(Nivel.output['Nivel'])\n",
    "            DATOS.iloc[i,2] = Nivel_In.iloc[i, dia]\n",
    "            DATOS.iloc[i,3] = float(Nivel.output['Nivel'])\n",
    "            \n",
    "    if N_Variables == 3:\n",
    "        #Parametros para pdf\n",
    "        text = \"2Variables_P(t-1,t-2)\"\n",
    "        estaciones = f'{EstP}'\n",
    "        REGLAS = \"precipitación t-1 y t-2\"\n",
    "        # Parámetros para pronóstico\n",
    "        reglas = [B, MB, M, A, B2, MB2, M2, A2]\n",
    "        def FL(i, dia):\n",
    "            Nivel.input['Precipitación Pasada'] = Prec_In.iloc[i, dia]\n",
    "            Nivel.input['Precipitación Pasada2'] = Prec_In2.iloc[i, dia]\n",
    "            Nivel.compute()\n",
    "            Pronosticos.iloc[i, dia] = float(Nivel.output['Nivel'])\n",
    "            DATOS.iloc[i,0] = Prec_In.iloc[i, dia]\n",
    "            DATOS.iloc[i,1] = Prec_In2.iloc[i, dia]\n",
    "            DATOS.iloc[i,3] = float(Nivel.output['Nivel'])   \n",
    "        \n",
    "    if N_Variables == 4:\n",
    "        #Parametros para pdf\n",
    "        text = \"2Variables_P(t-1)_N(t-1)\"\n",
    "        estaciones = f'{EstP}, {EstN}'\n",
    "        REGLAS = \"precipitación t-1 y nivel t-1\"\n",
    "        # Parámetros para pronóstico\n",
    "        reglas = [B, MB, M, A, Bn, MBn, Mn, An]\n",
    "        def FL(i, dia):\n",
    "            Nivel.input['Precipitación Pasada'] = Prec_In.iloc[i, dia]\n",
    "            Nivel.input['Nivel Pasado'] = Nivel_In.iloc[i, dia]\n",
    "            Nivel.compute()\n",
    "            Pronosticos.iloc[i, dia] = float(Nivel.output['Nivel'])\n",
    "            Nivel_In.iloc[i, dia + 1] = float(Nivel.output['Nivel'])\n",
    "            DATOS.iloc[i,0] = Prec_In.iloc[i, dia]\n",
    "            DATOS.iloc[i,2] = Nivel_In.iloc[i, dia]\n",
    "            DATOS.iloc[i,3] = float(Nivel.output['Nivel']) \n",
    "            \n",
    "    if N_Variables == 5:\n",
    "        #Parametros para pdf\n",
    "        text = \"3Variables_P(t-1,t-2)_C(t-1)\"\n",
    "        estaciones = f'{EstP}, {EstN}'\n",
    "        REGLAS = \"precipitación t-1, t-2 y caudal t-1\"\n",
    "        # Parámetros para pronóstico\n",
    "        reglas = [B, MB, M, A, B2, MB2, M2, A2, Bn, MBn, Mn, An]\n",
    "        def FL(i, dia):\n",
    "            Nivel.input['Precipitación Pasada'] = Prec_In.iloc[i, dia]\n",
    "            Nivel.input['Precipitación Pasada2'] = Prec_In2.iloc[i, dia]\n",
    "            Nivel.input['Nivel Pasado'] = Nivel_In.iloc[i, dia]\n",
    "            Nivel.compute()\n",
    "            Pronosticos.iloc[i, dia] = float(Nivel.output['Nivel'])\n",
    "            Nivel_In.iloc[i, dia + 1] = float(Nivel.output['Nivel'])\n",
    "            DATOS.iloc[i,0] = Prec_In.iloc[i, dia]\n",
    "            DATOS.iloc[i,1] = Prec_In2.iloc[i, dia]\n",
    "            DATOS.iloc[i,2] = Nivel_In.iloc[i, dia]\n",
    "            DATOS.iloc[i,3] = float(Nivel.output['Nivel'])\n",
    "    \n",
    "    Nivel_ctrl = ctrl.ControlSystem(reglas)\n",
    "    Nivel = ctrl.ControlSystemSimulation(Nivel_ctrl)\n",
    "    \n",
    "    NR = pd.DataFrame(index=DatosPrec[EstP].iloc[-dias_pasados:].index, columns=range(dias_futuros))\n",
    "    PR = pd.DataFrame(index=DatosPrec[EstP].iloc[-dias_pasados:].index, columns=range(dias_futuros))\n",
    "    \n",
    "    for i in range(dias_futuros):\n",
    "        NR.iloc[:dias_pasados-i,i] = DatosNiv[EstN].iloc[-dias_pasados+i:].values\n",
    "        PR.iloc[:dias_pasados-i,i] = DatosPrec[EstP].iloc[-dias_pasados+i:].values\n",
    "\n",
    "    NR = NR.astype(float)\n",
    "    PR = PR.astype(float)\n",
    "    \n",
    "    Prec_In = pd.DataFrame(index=DatosPrec[EstP].iloc[-dias_pasados:].index, columns=range(dias_futuros))\n",
    "    Prec_In2 = pd.DataFrame(index=DatosPrec[EstP].iloc[-dias_pasados-1:-1].index, columns=range(dias_futuros))\n",
    "    Nivel_In = pd.DataFrame(index=DatosPrec[EstP].iloc[-dias_pasados:].index, columns=range(dias_futuros + 1))\n",
    "    \n",
    "    # Asignar valores de t-1 y t-2 (reales)\n",
    "    Prec_In[0] = DatosPrec[EstP].iloc[-dias_pasados:].values.flatten()  \n",
    "    Prec_In2[0] = DatosPrec[EstP].iloc[-dias_pasados-1:-1].values.flatten()\n",
    "    Prec_In2[1] = DatosPrec[EstP].iloc[-dias_pasados:].values.flatten()\n",
    "    Nivel_In[0] = DatosNiv[EstN].iloc[-dias_pasados:].values.flatten() \n",
    "    \n",
    "    # Asignar predicciones a las columnas restantes\n",
    "    for i in range(dias_pasados):\n",
    "        Prec_In.iloc[i, 1:] = test_predict_unscaled[-dias_pasados+i, :]\n",
    "        Prec_In2.iloc[i, 2:] = test_predict_unscaled[-dias_pasados-1+i, 1:]\n",
    "    \n",
    "    DATOS = pd.DataFrame(index=DatosPrec[EstP].iloc[-dias_pasados:].index, columns=['Prec_t-1', 'Prec_t-2', 'Niv_t-1', 'Pronostico'])\n",
    "    \n",
    "    for i in range(dias_pasados):\n",
    "        \n",
    "        a = dias_pasados - i\n",
    "        \n",
    "        for dia in range(dias_futuros):\n",
    "            \n",
    "            FL(i, dia)\n",
    "        \n",
    "    # Calcular las métricas RMSE, MAE y R²\n",
    "    metrics = {'RMSE': [], 'MAE': [], 'R²': [], 'NSlog': [], 'PBIAS': [], 'MAPE': [], 'RMSPE': []}\n",
    "\n",
    "    for day in range(dias_futuros):\n",
    "\n",
    "        a = dias_pasados - day\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(NR.iloc[:a, day], Pronosticos.iloc[:a, day]))\n",
    "        mae = mean_absolute_error(NR.iloc[:a, day], Pronosticos.iloc[:a, day])\n",
    "        r2 = r2_score(NR.iloc[:a, day], Pronosticos.iloc[:a, day])\n",
    "        nr_log = np.log(NR.iloc[:a, day] + 1)\n",
    "        pred_log = np.log(Pronosticos.iloc[:a, day] + 1)\n",
    "        nslog = 1 - (np.sum((nr_log - pred_log) ** 2) / np.sum((nr_log - np.mean(nr_log)) ** 2))\n",
    "        pbias = 100 * (np.sum(NR.iloc[:a, day] - Pronosticos.iloc[:a, day]) / np.sum(NR.iloc[:a, day]))\n",
    "        mape = 100 * np.mean(np.abs((NR.iloc[:a, day] - Pronosticos.iloc[:a, day]) / NR.iloc[:a, day]))\n",
    "        rmspe = 100 * np.sqrt(np.mean(((NR.iloc[:a, day] - Pronosticos.iloc[:a, day]) / NR.iloc[:a, day]) ** 2))\n",
    "        metrics['RMSE'].append(rmse)\n",
    "        metrics['MAE'].append(mae)\n",
    "        metrics['R²'].append(r2)\n",
    "        metrics['NSlog'].append(nslog)\n",
    "        metrics['PBIAS'].append(pbias)\n",
    "        metrics['MAPE'].append(mape)\n",
    "        metrics['RMSPE'].append(rmspe)\n",
    "        \n",
    "        print(f\"Día {day + 1} - RMSE: {rmse}, MAE: {mae}, R²: {r2}, NSlog: {nslog}, PBIAS: {pbias}, MAPE: {mape}, RMSPE: {rmspe}\")\n",
    "   \n",
    "    return NR, Pronosticos, PrecP, Niv, metrics, text, estaciones, REGLAS\n",
    "\n",
    "def confianza2():\n",
    "    # Definir los percentiles del eje X\n",
    "    percentiles_x = [2.5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 97.5]\n",
    "    percentiles_labels = ['P2.5', 'P10', 'P20', 'P30', 'P40', 'P50', 'P60', 'P70', 'P80', 'P90', 'P97.5']\n",
    "\n",
    "    # Obtener percentiles reales\n",
    "    real = NR.iloc[-len(Pronosticos):,0]\n",
    "    percentilesR = np.percentile(real, percentiles_x)\n",
    "\n",
    "    # Crear DataFrames para cada día y calcular percentiles y rangos en bucle\n",
    "    dias_percentiles = {}\n",
    "    for dia in range(1, dias_futuros+1):\n",
    "        # Ordenar los valores pronosticados\n",
    "        ordenados = Pronosticos.iloc[:, dia - 1].dropna().sort_values(ascending=True).reset_index(drop=True)\n",
    "\n",
    "        # Crear un DataFrame para cada día\n",
    "        dia_df = pd.DataFrame({'Nombre': percentiles_labels})\n",
    "\n",
    "        # Calcular los percentiles\n",
    "        dia_df['percentiles'] = [np.percentile(ordenados, i) for i in percentiles_x]\n",
    "\n",
    "        # Función para calcular los rangos C10, C90, C5, C95\n",
    "        def calcular_rang(ordenados, percentil, percentiles_x):\n",
    "            # Obtener el percentil anterior\n",
    "            if percentil == percentiles_x[0]:\n",
    "                p_anterior = 0\n",
    "            else:\n",
    "                p_anterior = np.percentile(ordenados, percentiles_x[percentiles_x.index(percentil) - 1])\n",
    "\n",
    "            # Filtrar los datos que están en la marca de clase\n",
    "            p = ordenados[(ordenados <= np.percentile(ordenados, percentil)) & (ordenados > p_anterior)]\n",
    "\n",
    "            # Calcular los percentiles\n",
    "            c10 = np.percentile(p, 10) if len(p) > 0 else np.nan  # Verificar longitud para evitar errores\n",
    "            c90 = np.percentile(p, 90) if len(p) > 0 else np.nan\n",
    "            c5 = np.percentile(p, 5) if len(p) > 0 else np.nan\n",
    "            c95 = np.percentile(p, 95) if len(p) > 0 else np.nan\n",
    "            return c10, c90, c5, c95\n",
    "\n",
    "        # Calcular los rangos para cada percentil y agregar al DataFrame\n",
    "        dia_df[['C10', 'C90', 'C5', 'C95']] = [calcular_rang(ordenados, i, percentiles_x) for i in percentiles_x]\n",
    "\n",
    "        # Guardar el DataFrame del día en el diccionario\n",
    "        dias_percentiles[f'Dia_{dia}'] = dia_df\n",
    "\n",
    "    return dias_percentiles, percentilesR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03567f8b-cbe3-48ac-9159-e02ae869f6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo seleccionado: C:/Users/juanj/Downloads/Estaciones/Estaciones/H5025/Seleccionado/Niveles_H5025_relleno.csv\n",
      "Archivo seleccionado: C:/Users/juanj/Downloads/Estaciones/Estaciones/H5025/Seleccionado/Niveles_H5025_relleno.csv\n",
      "Has seleccionado la estación: 5025\n",
      "Archivo seleccionado: C:/Users/juanj/Downloads/Estaciones/Estaciones/H5025/Seleccionado/serie_ponderada_geom_P39.csv\n",
      "Has seleccionado la estación: Precipitacion_Ponderada\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ingrese el número de días futuros:  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "152/152 - 14s - loss: 0.0500 - val_loss: 0.0499 - 14s/epoch - 89ms/step\n",
      "Epoch 2/10\n",
      "152/152 - 7s - loss: 0.0496 - val_loss: 0.0504 - 7s/epoch - 43ms/step\n",
      "Epoch 3/10\n",
      "152/152 - 7s - loss: 0.0495 - val_loss: 0.0497 - 7s/epoch - 45ms/step\n",
      "Epoch 4/10\n",
      "152/152 - 7s - loss: 0.0496 - val_loss: 0.0499 - 7s/epoch - 44ms/step\n",
      "Epoch 5/10\n",
      "152/152 - 7s - loss: 0.0495 - val_loss: 0.0492 - 7s/epoch - 46ms/step\n",
      "Epoch 6/10\n",
      "152/152 - 7s - loss: 0.0493 - val_loss: 0.0503 - 7s/epoch - 45ms/step\n",
      "Epoch 7/10\n",
      "152/152 - 7s - loss: 0.0493 - val_loss: 0.0494 - 7s/epoch - 44ms/step\n",
      "Epoch 8/10\n",
      "152/152 - 7s - loss: 0.0493 - val_loss: 0.0500 - 7s/epoch - 45ms/step\n",
      "Epoch 9/10\n",
      "152/152 - 7s - loss: 0.0492 - val_loss: 0.0492 - 7s/epoch - 44ms/step\n",
      "Epoch 10/10\n",
      "152/152 - 7s - loss: 0.0493 - val_loss: 0.0500 - 7s/epoch - 45ms/step\n",
      "10/10 [==============================] - 1s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "Datos_Historicos_Nivel = LeerArchivos(\"datos historicos de nivel\")\n",
    "DatosNiv = LeerArchivos(\"periodo seleccionado de nivel\")\n",
    "EstN = ElegirEstacion(DatosNiv, \"nivel\")\n",
    "DatosPrec = LeerArchivos(\"periodo seleccionado de precipitacion\")\n",
    "EstP = ElegirEstacion(DatosPrec, \"precipitación\")\n",
    "\n",
    "dias_futuros = int(input(\"Ingrese el número de días futuros: \"))\n",
    "\n",
    "test_predict_unscaled = ANN()\n",
    "dias_pasados = len(test_predict_unscaled) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f556b9ae-d8b0-4c22-9f4b-56fbaefe1f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "¿Con qué variables desea trabajar?:\n",
      "1. Precipitación t-1\n",
      "2. Nivel t-1\n",
      "3. Precipitación t-1, t-2\n",
      "4. Precipitación t-1 y nivel t-1\n",
      "5. Precipitación t-1, t-2 y nivel t-1\n",
      " 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Día 1 - RMSE: 0.040678650104646566, MAE: 0.02601783502492101, R²: 0.7410363597041415, NSlog: 0.749226773997894, PBIAS: -6.533397731219205, MAPE: 8.465094156747478, RMSPE: 13.052744849867008\n",
      "Día 2 - RMSE: 0.08100547986930501, MAE: 0.05381303435787231, R²: -0.02623890750326896, NSlog: 0.05952550415075086, PBIAS: -8.824132693632437, MAPE: 16.02385757148335, RMSPE: 22.340063564467144\n",
      "Día 3 - RMSE: 0.11744311489629695, MAE: 0.07555782130464901, R²: -1.1561404166636744, NSlog: -0.9343289701920197, PBIAS: -10.962697316537806, MAPE: 22.22658849601653, RMSPE: 32.89557312204718\n",
      "Día 4 - RMSE: 0.12771047758803736, MAE: 0.08250165617178286, R²: -1.5491104866376237, NSlog: -1.3060078510961053, PBIAS: -11.134705588015645, MAPE: 24.63895455670794, RMSPE: 37.10089988350845\n",
      "Día 5 - RMSE: 0.1337588038929731, MAE: 0.08644435847954861, R²: -1.7955335093701312, NSlog: -1.54088495104221, PBIAS: -11.05812888705132, MAPE: 26.107498417488845, RMSPE: 40.04321462978459\n",
      "Día 6 - RMSE: 0.13492401775559526, MAE: 0.08872589887762977, R²: -1.8409059062055255, NSlog: -1.5867710749626474, PBIAS: -11.286189226571459, MAPE: 27.080979489415196, RMSPE: 41.3549521981181\n",
      "Día 7 - RMSE: 0.13575878139493827, MAE: 0.08952005236699125, R²: -1.8710438521012933, NSlog: -1.6209120273620212, PBIAS: -11.494471246360744, MAPE: 27.57230755667678, RMSPE: 42.28884929960589\n"
     ]
    }
   ],
   "source": [
    "Percentiles = []\n",
    "\n",
    "Percentiles, rangos = CDG(DatosNiv, 4, 19, 71, 0)\n",
    "Percentiles, rangos = CDG(DatosPrec, 0, 1, 5, 1)\n",
    "\n",
    "NR, Pronosticos, PrecP, Niv, metrics, text, estaciones, REGLAS = LogicaDifusa(DatosPrec, DatosNiv)\n",
    "dias_percentiles, percentilesR = confianza2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "962ac310-43de-4726-ae5c-e60c62e9d5a4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 50 90\n",
      "0 98 99\n",
      "Día 1 - RMSE: 7.869690441308257, MAE: 6.145781464527271, R²: 0.6312842532201668\n",
      "Día 2 - RMSE: 12.72513306392941, MAE: 9.483981561443082, R²: 0.03948944700502721\n",
      "Día 3 - RMSE: 17.29502404481021, MAE: 12.666376665758698, R²: -0.7681383671225115\n",
      "Día 4 - RMSE: 19.48000507547066, MAE: 14.294867818758734, R²: -1.2348239828803056\n",
      "Día 5 - RMSE: 20.530669519661213, MAE: 14.811119739668394, R²: -1.4732293077214416\n",
      "Día 6 - RMSE: 21.05161959288528, MAE: 15.153565169209553, R²: -1.5909164530585462\n",
      "Día 7 - RMSE: 21.065844588344596, MAE: 15.421012860511485, R²: -1.5849570413051928\n",
      "Mejorado R2 (Niv) con val1: 10, val2: 50, val3: 90 -> R2: 0.6312842532201668\n",
      "9 50 90\n",
      "0 98 99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 100\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mejores_params_niv, mejores_params_prec, mejor_r2\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Llamada a la función de optimización\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m mejores_params_niv, mejores_params_prec, mejor_r2 \u001b[38;5;241m=\u001b[39m \u001b[43moptimizar_cdg_secuencial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDatosPrec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDatosNiv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMejores parámetros CDG(DatosNiv): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmejores_params_niv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMejores parámetros CDG(DatosPrec): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmejores_params_prec\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[74], line 90\u001b[0m, in \u001b[0;36moptimizar_cdg_secuencial\u001b[1;34m(DatosPrec, DatosNiv)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Optimización para CDG(DatosNiv, ...)\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m \u001b[43moptimizar_niv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Optimización para CDG(DatosPrec, ...)\u001b[39;00m\n\u001b[0;32m     93\u001b[0m optimizar_prec()\n",
      "Cell \u001b[1;32mIn[74], line 28\u001b[0m, in \u001b[0;36moptimizar_cdg_secuencial.<locals>.optimizar_niv\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(val1_niv, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     27\u001b[0m     Percentiles \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 28\u001b[0m     r2_actual, Percentiles \u001b[38;5;241m=\u001b[39m \u001b[43mcalcular_r2_y_mejorar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval2_niv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval3_niv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval1_prec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval2_prec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval3_prec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDatosPrec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDatosNiv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m r2_actual \u001b[38;5;241m>\u001b[39m mejor_r2:\n\u001b[0;32m     30\u001b[0m         mejor_r2 \u001b[38;5;241m=\u001b[39m r2_actual\n",
      "Cell \u001b[1;32mIn[74], line 17\u001b[0m, in \u001b[0;36moptimizar_cdg_secuencial.<locals>.calcular_r2_y_mejorar\u001b[1;34m(val1_niv, val2_niv, val3_niv, val1_prec, val2_prec, val3_prec, DatosPrec, DatosNiv)\u001b[0m\n\u001b[0;32m     14\u001b[0m Percentiles \u001b[38;5;241m=\u001b[39m CDG(DatosNiv, val1_niv, val2_niv, val3_niv)\n\u001b[0;32m     15\u001b[0m Percentiles \u001b[38;5;241m=\u001b[39m CDG(DatosPrec, val1_prec, val2_prec, val3_prec)\n\u001b[1;32m---> 17\u001b[0m NR, Pronosticos, PrecP, Niv, metrics, text, estaciones, REGLAS \u001b[38;5;241m=\u001b[39m \u001b[43mLogicaDifusa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDatosPrec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDatosNiv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Extraemos el valor de r2 de \"metrics\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR²\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], Percentiles\n",
      "Cell \u001b[1;32mIn[52], line 320\u001b[0m, in \u001b[0;36mLogicaDifusa\u001b[1;34m(P, N)\u001b[0m\n\u001b[0;32m    316\u001b[0m     a \u001b[38;5;241m=\u001b[39m dias_pasados \u001b[38;5;241m-\u001b[39m i\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dia \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dias_futuros):\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mFL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdia\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# Calcular las métricas RMSE, MAE y R²\u001b[39;00m\n\u001b[0;32m    323\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR²\u001b[39m\u001b[38;5;124m'\u001b[39m: []}\n",
      "Cell \u001b[1;32mIn[52], line 281\u001b[0m, in \u001b[0;36mLogicaDifusa.<locals>.FL\u001b[1;34m(i, dia)\u001b[0m\n\u001b[0;32m    279\u001b[0m Nivel\u001b[38;5;241m.\u001b[39minput[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecipitación Pasada2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m Prec_In2\u001b[38;5;241m.\u001b[39miloc[i, dia]\n\u001b[0;32m    280\u001b[0m Nivel\u001b[38;5;241m.\u001b[39minput[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNivel Pasado\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m Nivel_In\u001b[38;5;241m.\u001b[39miloc[i, dia]\n\u001b[1;32m--> 281\u001b[0m \u001b[43mNivel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m Pronosticos\u001b[38;5;241m.\u001b[39miloc[i, dia] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(Nivel\u001b[38;5;241m.\u001b[39moutput[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNivel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    283\u001b[0m Nivel_In\u001b[38;5;241m.\u001b[39miloc[i, dia \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(Nivel\u001b[38;5;241m.\u001b[39moutput[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNivel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\.conda\\envs\\Scikit-fuzzi\\lib\\site-packages\\skfuzzy\\control\\controlsystem.py:373\u001b[0m, in \u001b[0;36mControlSystemSimulation.compute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# Collect the results and present them as a dict\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m consequent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctrl\u001b[38;5;241m.\u001b[39mconsequents:\n\u001b[0;32m    372\u001b[0m     consequent\u001b[38;5;241m.\u001b[39moutput[\u001b[38;5;28mself\u001b[39m] \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m--> 373\u001b[0m         \u001b[43mCrispValueCalculator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconsequent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefuzz\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput[consequent\u001b[38;5;241m.\u001b[39mlabel] \u001b[38;5;241m=\u001b[39m consequent\u001b[38;5;241m.\u001b[39moutput[\u001b[38;5;28mself\u001b[39m]\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# Make note of this run so we can easily find it again\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\Scikit-fuzzi\\lib\\site-packages\\skfuzzy\\control\\controlsystem.py:578\u001b[0m, in \u001b[0;36mCrispValueCalculator.defuzz\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Derive crisp value based on membership of adjective(s).\"\"\"\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msim\u001b[38;5;241m.\u001b[39m_array_inputs:\n\u001b[1;32m--> 578\u001b[0m     ups_universe, output_mf, cut_mfs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_memberships\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cut_mfs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo terms have memberships.  Make sure you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave at least one rule connected to this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    583\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable and have run the rules calculation.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\Scikit-fuzzi\\lib\\site-packages\\skfuzzy\\control\\controlsystem.py:635\u001b[0m, in \u001b[0;36mCrispValueCalculator.find_memberships\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# No membership defined for this adjective\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;66;03m# Faster to aggregate as list w/duplication\u001b[39;00m\n\u001b[0;32m    634\u001b[0m     new_values\u001b[38;5;241m.\u001b[39mextend(\n\u001b[1;32m--> 635\u001b[0m         \u001b[43m_interp_universe_fast\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cut\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m    638\u001b[0m new_universe \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munion1d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar\u001b[38;5;241m.\u001b[39muniverse, new_values)\n\u001b[0;32m    640\u001b[0m \u001b[38;5;66;03m# Initilize membership\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\Scikit-fuzzi\\lib\\site-packages\\skfuzzy\\fuzzymath\\fuzzy_ops.py:654\u001b[0m, in \u001b[0;36m_interp_universe_fast\u001b[1;34m(x, xmf, y)\u001b[0m\n\u001b[0;32m    652\u001b[0m     idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(np\u001b[38;5;241m.\u001b[39mdiff(xmf \u001b[38;5;241m>\u001b[39m y))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 654\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxmf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    656\u001b[0m \u001b[38;5;66;03m# This method is fast, but duplicates point values where\u001b[39;00m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;66;03m# y == peak of a membership function.\u001b[39;00m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x[idx] \u001b[38;5;241m+\u001b[39m (y\u001b[38;5;241m-\u001b[39mxmf[idx]) \u001b[38;5;241m*\u001b[39m (x[idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mx[idx]) \u001b[38;5;241m/\u001b[39m (xmf[idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mxmf[idx])\n",
      "File \u001b[1;32m~\\.conda\\envs\\Scikit-fuzzi\\lib\\site-packages\\numpy\\core\\multiarray.py:346\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(condition, x, y)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124;03m    inner(a, b, /)\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    341\u001b[0m \n\u001b[0;32m    342\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, b)\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;129m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath\u001b[38;5;241m.\u001b[39mwhere)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwhere\u001b[39m(condition, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    348\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03m    where(condition, [x, y], /)\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m           [ 0,  3, -1]])\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (condition, x, y)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def optimizar_cdg_secuencial(DatosPrec, DatosNiv):\n",
    "    # Parámetros iniciales para ambos CDG (empiezan en 97, 98, 99)\n",
    "    val1_niv, val2_niv, val3_niv = 10, 50, 90\n",
    "    val1_prec, val2_prec, val3_prec = 0, 98, 99\n",
    "    mejor_r2 = -np.inf\n",
    "    mejores_params_niv = (val1_niv, val2_niv, val3_niv)\n",
    "    mejores_params_prec = (val1_prec, val2_prec, val3_prec)\n",
    "    \n",
    "    # Función auxiliar para calcular el R2 y verificar si mejora\n",
    "    def calcular_r2_y_mejorar(val1_niv, val2_niv, val3_niv, val1_prec, val2_prec, val3_prec, DatosPrec, DatosNiv):\n",
    "        # Ejecutamos las funciones CDG con los valores actuales\n",
    "        Percentiles = []\n",
    "\n",
    "        Percentiles = CDG(DatosNiv, val1_niv, val2_niv, val3_niv)\n",
    "        Percentiles = CDG(DatosPrec, val1_prec, val2_prec, val3_prec)\n",
    "\n",
    "        NR, Pronosticos, PrecP, Niv, metrics, text, estaciones, REGLAS = LogicaDifusa(DatosPrec, DatosNiv)\n",
    "\n",
    "        # Extraemos el valor de r2 de \"metrics\"\n",
    "        return metrics['R²'][0], Percentiles  # Ajusta según la estructura de 'metrics'\n",
    "\n",
    "    # Proceso de optimización de CDG(DatosNiv, val1_niv, val2_niv, val3_niv)\n",
    "    def optimizar_niv():\n",
    "        nonlocal mejor_r2, mejores_params_niv\n",
    "        # Optimizar primero val1\n",
    "        for v1 in range(val1_niv, 0, -1):\n",
    "            r2_actual, Percentiles = calcular_r2_y_mejorar(v1, val2_niv, val3_niv, val1_prec, val2_prec, val3_prec, DatosPrec, DatosNiv)\n",
    "            if r2_actual > mejor_r2:\n",
    "                mejor_r2 = r2_actual\n",
    "                mejores_params_niv = (v1, val2_niv, val3_niv)\n",
    "                print(f\"Mejorado R2 (Niv) con val1: {v1}, val2: {val2_niv}, val3: {val3_niv} -> R2: {mejor_r2}\")\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # Optimizar val2 (siempre debe ser mayor que val1)\n",
    "        for v2 in range(val2_niv, mejores_params_niv[0], -1):\n",
    "            r2_actual, Percentiles = calcular_r2_y_mejorar(mejores_params_niv[0], v2, val3_niv, val1_prec, val2_prec, val3_prec, DatosPrec, DatosNiv)\n",
    "            if r2_actual > mejor_r2:\n",
    "                mejor_r2 = r2_actual\n",
    "                mejores_params_niv = (mejores_params_niv[0], v2, val3_niv)\n",
    "                print(f\"Mejorado R2 (Niv) con val1: {mejores_params_niv[0]}, val2: {v2}, val3: {val3_niv} -> R2: {mejor_r2}\")\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # Optimizar val3 (siempre debe ser mayor que val2)\n",
    "        for v3 in range(val3_niv, mejores_params_niv[1], -1):\n",
    "            r2_actual, Percentiles = calcular_r2_y_mejorar(mejores_params_niv[0], mejores_params_niv[1], v3, val1_prec, val2_prec, val3_prec, DatosPrec, DatosNiv)\n",
    "            if r2_actual > mejor_r2:\n",
    "                mejor_r2 = r2_actual\n",
    "                mejores_params_niv = (mejores_params_niv[0], mejores_params_niv[1], v3)\n",
    "                print(f\"Mejorado R2 (Niv) con val1: {mejores_params_niv[0]}, val2: {mejores_params_niv[1]}, val3: {v3} -> R2: {mejor_r2}\")\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    # Proceso de optimización de CDG(DatosPrec, val1_prec, val2_prec, val3_prec)\n",
    "    def optimizar_prec():\n",
    "        nonlocal mejor_r2, mejores_params_prec\n",
    "        # Optimizar primero val1_prec\n",
    "        for v1 in range(val1_prec, 0, -1):\n",
    "            r2_actual, Percentiles = calcular_r2_y_mejorar(mejores_params_niv[0], mejores_params_niv[1], mejores_params_niv[2], v1, val2_prec, val3_prec, DatosPrec, DatosNiv)\n",
    "            if r2_actual > mejor_r2:\n",
    "                mejor_r2 = r2_actual\n",
    "                mejores_params_prec = (v1, val2_prec, val3_prec)\n",
    "                print(f\"Mejorado R2 (Prec) con val1: {v1}, val2: {val2_prec}, val3: {val3_prec} -> R2: {mejor_r2}\")\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # Optimizar val2 (siempre debe ser mayor que val1)\n",
    "        for v2 in range(val2_prec, mejores_params_prec[0], -1):\n",
    "            r2_actual, Percentiles = calcular_r2_y_mejorar(mejores_params_niv[0], mejores_params_niv[1], mejores_params_niv[2], mejores_params_prec[0], v2, val3_prec, DatosPrec, DatosNiv)\n",
    "            if r2_actual > mejor_r2:\n",
    "                mejor_r2 = r2_actual\n",
    "                mejores_params_prec = (mejores_params_prec[0], v2, val3_prec)\n",
    "                print(f\"Mejorado R2 (Prec) con val1: {mejores_params_prec[0]}, val2: {v2}, val3: {val3_prec} -> R2: {mejor_r2}\")\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # Optimizar val3 (siempre debe ser mayor que val2)\n",
    "        for v3 in range(val3_prec, mejores_params_prec[1], -1):\n",
    "            r2_actual, Percentiles = calcular_r2_y_mejorar(mejores_params_niv[0], mejores_params_niv[1], mejores_params_niv[2], mejores_params_prec[0], mejores_params_prec[1], v3, DatosPrec, DatosNiv)\n",
    "            if r2_actual > mejor_r2:\n",
    "                mejor_r2 = r2_actual\n",
    "                mejores_params_prec = (mejores_params_prec[0], mejores_params_prec[1], v3)\n",
    "                print(f\"Mejorado R2 (Prec) con val1: {mejores_params_prec[0]}, val2: {mejores_params_prec[1]}, val3: {v3} -> R2: {mejor_r2}\")\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    # Optimización para CDG(DatosNiv, ...)\n",
    "    optimizar_niv()\n",
    "\n",
    "    # Optimización para CDG(DatosPrec, ...)\n",
    "    optimizar_prec()\n",
    "\n",
    "    return mejores_params_niv, mejores_params_prec, mejor_r2\n",
    "\n",
    "# Llamada a la función de optimización\n",
    "\n",
    "\n",
    "mejores_params_niv, mejores_params_prec, mejor_r2 = optimizar_cdg_secuencial(DatosPrec, DatosNiv)\n",
    "print(f\"Mejores parámetros CDG(DatosNiv): {mejores_params_niv}\")\n",
    "print(f\"Mejores parámetros CDG(DatosPrec): {mejores_params_prec}\")\n",
    "print(f\"Mejor R2 obtenido: {mejor_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584de450-b28c-48dc-8e73-bc09b1262268",
   "metadata": {},
   "source": [
    "# Generar PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fbebfb1-e691-4f86-86ac-59ce155cac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juanj\\.conda\\envs\\Scikit-fuzzi\\lib\\site-packages\\matplotlib\\figure.py:456: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  warnings.warn(\n",
      "C:\\Users\\juanj\\.conda\\envs\\Scikit-fuzzi\\lib\\site-packages\\matplotlib\\figure.py:456: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados y gráficos guardados en el archivo Precipitacion_Ponderada_Historico_3Variables_P(t-1,t-2)_C(t-1).pdf.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generar nombre del archivo PDF dinámico basado en variables y nombres de las columnas\n",
    "pdf_filename = f'{EstP}_Historico_{text}.pdf'\n",
    "\n",
    "# Crear el archivo PDF para guardar gráficos y métricas\n",
    "with PdfPages(pdf_filename) as pdf:\n",
    "    # Página 1: Información general\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.text(0.5, 0.9, 'Variables Utilizadas en el Pronóstico:', ha='center', fontsize=14)\n",
    "    plt.text(0.5, 0.8, f'{estaciones}', ha='center', fontsize=12)\n",
    "    plt.text(0.5, 0.7, f'Variable Pronosticada: Nivel en estación {EstN}', ha='center', fontsize=14)\n",
    "    plt.text(0.5, 0.6, f'Reglas basadas en {REGLAS}', ha='center', fontsize=14)\n",
    "    plt.text(0.5, 0.5, f'Rangos de: Nivel{rangos.iloc[0,0]}, Precipitación{rangos.iloc[1,0]}', ha='center', fontsize=12)\n",
    "    plt.text(0.5, 0.4, 'Métricas de Ajuste:', ha='center', fontsize=14)\n",
    "    for i in range(dias_futuros):\n",
    "        plt.text(0.5, 0.3 - i*0.05, f\"Día {i + 1} - RMSE: {metrics['RMSE'][i]:.4f}, MAE: {metrics['MAE'][i]:.4f}, R²: {metrics['R²'][i]:.4f}, NSlog: {metrics['NSlog'][i]:.4f}, PBIAS: {metrics['PBIAS'][i]:.4f}, MAPE: {metrics['MAPE'][i]:.4f}%, RMSPE: {metrics['RMSPE'][i]:.4f}\" ,\n",
    "                 ha='center', fontsize=11)\n",
    "    plt.axis('off')\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "    \n",
    "   # Gráficos de predicción e intervalos de confianza\n",
    "    for day in range(dias_futuros):\n",
    "\n",
    "        a = dias_pasados - day\n",
    "        Dia = dias_percentiles[f'Dia_{day+1}']\n",
    "\n",
    "        # Crear subplots: 1 fila y 2 columnas\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "        # Gráfico 1: Pronóstico vs Realidad\n",
    "        ax1.set_title(f'Pronóstico del Día {day+1}')\n",
    "        ax1.plot(DatosPrec.index[-len(NR):], NR.iloc[:, 0], label= 'Nivel Real')\n",
    "        ax1.plot(DatosPrec.index[-len(NR):], Pronosticos.iloc[:, day], label= 'Pronóstico', color='red')\n",
    "        ax1.set_xlabel('Fecha')\n",
    "        ax1.set_ylabel('Nivel (m)')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "\n",
    "        # Gráfico 2: Intervalos de confianza\n",
    "        ax2.set_title(f'Día {day+1} - Intervalo de Confianza')\n",
    "        ax2.plot(Dia['Nombre'], percentilesR, label='Nivel real', color='black', linewidth=1.5)\n",
    "\n",
    "        # Graficar los intervalos de confianza\n",
    "        ax2.fill_between(Dia['Nombre'], Dia['C10'], Dia['C90'], color='blue', alpha=0.2, label='C10-C90')\n",
    "        ax2.fill_between(Dia['Nombre'], Dia['C5'], Dia['C95'], color='gray', alpha=0.2, label='C5-C95')\n",
    "\n",
    "        ax2.set_xlabel('Percentil')\n",
    "        ax2.set_ylabel('Nivel (m)')\n",
    "        ax2.legend(loc='upper left')\n",
    "        ax2.grid(True)\n",
    "\n",
    "        # Ajustar el espaciado entre los subplots\n",
    "        plt.tight_layout()\n",
    "\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "        \n",
    "    # Gráfico de MAE, RMSE, R²\n",
    "    days = range(1, dias_futuros + 1)\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "    # Gráfico de RMSE y MAE en el eje primario\n",
    "    ax1.plot(days, metrics['RMSE'], label='RMSE', color='b')\n",
    "    ax1.plot(days, metrics['MAE'], label='MAE', color='g')\n",
    "    ax1.set_xlabel('Día de Pronóstico')\n",
    "    ax1.set_ylabel('RMSE / MAE', color='black')\n",
    "    ax1.tick_params(axis='y', labelcolor='black')\n",
    "    ax1.grid(True)\n",
    "    # Crear el segundo eje (eje secundario) para R²\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(days, metrics['R²'], label='R²', color='r')\n",
    "    ax2.set_ylabel('R²', color='black')\n",
    "    ax2.tick_params(axis='y', labelcolor='black')\n",
    "    # Añadir leyendas para cada eje\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    # Título de la gráfica\n",
    "    plt.title('Métricas de Pronóstico para Cada Día')\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # Gráfico de NSlog, RMSPE, MAPE\n",
    "    days = range(1, dias_futuros + 1)\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "    # Gráfico de RMSPE y MAPE en el eje primario\n",
    "    ax1.plot(days, metrics['RMSPE'], label='RMPSE', color='b')\n",
    "    ax1.plot(days, metrics['MAPE'], label='MAPE', color='g')\n",
    "    ax1.set_xlabel('Día de Pronóstico')\n",
    "    ax1.set_ylabel('RMSPE / MAPE', color='black')\n",
    "    ax1.tick_params(axis='y', labelcolor='black')\n",
    "    ax1.grid(True)\n",
    "    # Crear el segundo eje (eje secundario) para R²\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(days, metrics['NSlog'], label='NSlog', color='r')\n",
    "    ax2.set_ylabel('NSlog', color='black')\n",
    "    ax2.tick_params(axis='y', labelcolor='black')\n",
    "    # Añadir leyendas para cada eje\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    # Título de la gráfica\n",
    "    plt.title('Métricas de Pronóstico para Cada Día')\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # Gráfico de PBIAS\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    days = range(1, 8)\n",
    "    plt.plot(days, metrics['PBIAS'], label='PBIAS')\n",
    "    plt.title('Métricas de Pronóstico para Cada Día')\n",
    "    plt.xlabel('Día de Pronóstico')\n",
    "    plt.ylabel('Métrica')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "    \n",
    "    # Gráfico membresías de precipitación y nivel\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    Niv.view()\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    PrecP.view()\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "    \n",
    "# Mensaje de finalización\n",
    "print(f\"Resultados y gráficos guardados en el archivo {pdf_filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f6bfe1-b8db-402a-81d2-ac202f361c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
