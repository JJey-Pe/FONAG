{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f643d36-8229-4883-be24-8670387ce46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import ttk\n",
    "import pandas as pd\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "rangos = pd.DataFrame(index=range(2), columns=range(1))\n",
    "\n",
    "def CDG(df, a, b, c, d):\n",
    "\n",
    "    # Diccionario de DF por cada estaciÃ³n\n",
    "    Estaciones = {}\n",
    "    percent = {}\n",
    "    # Percentilies deseados\n",
    "    Prob = [a, b, c]\n",
    "    for columna in df.columns:\n",
    "        # Crear un DataFrame para cada estaciÃ³n y ordenarlo\n",
    "        est = df[[columna]].dropna().sort_values(by=columna, ascending=False).reset_index(drop=True)\n",
    "        est = est.iloc[:-3,:]\n",
    "        est = est.iloc[1:,:]\n",
    "        est['Probabilidad'] = 100*(est.index + 1) / (len(est) + 1)\n",
    "        Estaciones[columna] = est\n",
    "            \n",
    "        i = 0\n",
    "        P = pd.DataFrame(np.zeros((len(Prob), 2)), columns=['Nivel', 'Probabilidad'])\n",
    "\n",
    "        for p in Prob:\n",
    "            idx = (est.iloc[:, 1] - p).abs().idxmin()\n",
    "            P.at[i, 'Nivel'] = float(\"{:.2f}\".format(est.iloc[idx, 0]))\n",
    "            P.at[i, 'Probabilidad'] = float(\"{:.2f}\".format(est.iloc[idx, 1]))\n",
    "            i = i + 1\n",
    "        percent[columna] = P.copy()\n",
    "    rangos.iloc[d,0] = str((a, b, c))\n",
    "    Percentiles.append(percent)\n",
    "    \n",
    "    return Percentiles, rangos  \n",
    "\n",
    "def LeerArchivos(a):\n",
    "    # Crear una ventana raíz\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Ocultar la ventana principal\n",
    "    # Hacer que la ventana esté siempre en el frente\n",
    "    root.attributes('-topmost', True)\n",
    "    # Abrir un cuadro de diálogo para seleccionar un archivo CSV\n",
    "    file_path = filedialog.askopenfilename(\n",
    "        title=f\"Selecciona un archivo CSV de {a}\",\n",
    "        filetypes=((\"CSV files\", \"*.csv\"), (\"Todos los archivos\", \"*.*\")))\n",
    "    # Mostrar la ruta del archivo seleccionado\n",
    "    print(f\"Archivo seleccionado: {file_path}\")\n",
    "\n",
    "    # Cerrar la ventana raíz\n",
    "    root.destroy()\n",
    "        \n",
    "    if file_path:  # Verificar si se seleccionó un archivo\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, index_col=None)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al leer el archivo: {e}\")\n",
    "    else:\n",
    "        print(\"No se seleccionó ningún archivo.\")\n",
    "        \n",
    "    df.iloc[:, 0] = pd.to_datetime(df.iloc[:,0])\n",
    "    df = df.set_index(df.columns[0])\n",
    "        \n",
    "    return df\n",
    "\n",
    "def ElegirEstacion(Data, a):\n",
    "    \n",
    "    def Seleccion():\n",
    "        columna_seleccionada = columna_var.get()\n",
    "        print(f\"Has seleccionado la estación: {columna_seleccionada}\")\n",
    "        root.destroy()  # Cierra la ventana\n",
    "    \n",
    "    # Crear la ventana principal de Tkinter\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Selecciona una estación de {a}\")\n",
    "    # Hacer que la ventana esté siempre en el frente\n",
    "    root.attributes('-topmost', True)\n",
    "    # Variable para almacenar la selección\n",
    "    columna_var = tk.StringVar()\n",
    "    columna_var.set(Data.columns[0])  # Valor inicial en el OptionMenu\n",
    "    dropdown = ttk.OptionMenu(root, columna_var, *Data.columns)\n",
    "    dropdown.pack(pady=10)\n",
    "    # Botón para confirmar la selección\n",
    "    boton = tk.Button(root, text=\"Seleccionar\", command = Seleccion)\n",
    "    boton.pack(pady=20)\n",
    "    # Iniciar la ventana\n",
    "    root.mainloop()\n",
    "    columna_seleccionada = columna_var.get()\n",
    "    \n",
    "    return columna_seleccionada\n",
    "\n",
    "def resample(N,P):\n",
    "    a = int(input(\"Ingrese el número de resampleo: \"))\n",
    "    DatosNiv = N.groupby(N.reset_index().index // a).mean().reset_index(drop=True)\n",
    "    DatosPrec = P.groupby(P.reset_index().index // a).sum().reset_index(drop=True)\n",
    "    \n",
    "    return DatosNiv, DatosPrec, a\n",
    "    \n",
    "\n",
    "def ANN():\n",
    "    # Escalar los datos entre 0 y 1\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    data_scaled = scaler.fit_transform(pd.DataFrame(DatosPrec[EstP]))\n",
    "    \n",
    "    # Dividir los datos en conjunto de entrenamiento y prueba (80% - 20%)\n",
    "    train_size = int(len(data_scaled) * 0.5)\n",
    "    train, test = data_scaled[:train_size], data_scaled[train_size:]\n",
    "    \n",
    "    # Crear una función para transformar los datos en formato adecuado para LSTM (multivariables)\n",
    "    def create_dataset(data, look_back=10, forecast_horizon=dias_futuros-1):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - look_back - forecast_horizon):\n",
    "            X.append(data[i:(i + look_back), :])  # Tomar todas las características\n",
    "            y.append(data[(i + look_back):(i + look_back + forecast_horizon), 0])  # Predecir la primera variable\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    # Usamos 90 días para predecir los próximos 7 días\n",
    "    look_back = 10\n",
    "    forecast_horizon = dias_futuros-1\n",
    "    X_train, y_train = create_dataset(train, look_back, forecast_horizon)\n",
    "    X_test, y_test = create_dataset(test, look_back, forecast_horizon)\n",
    "    \n",
    "    # Reshape para que el modelo LSTM lo entienda (samples, time steps, features)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "    \n",
    "    # Parámetros de entrenamiento\n",
    "    epochs = 20\n",
    "    batch_size = 5\n",
    "    \n",
    "    # Crear el modelo LSTM\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=(look_back, 1)))  # Hay 'num_vars' variables de entrada\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(forecast_horizon))  # Predecir los próximos 6 días\n",
    "    \n",
    "    # Compilar el modelo\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=2)\n",
    "    \n",
    "    # Realizar el pronóstico\n",
    "    test_predict = model.predict(X_test)\n",
    "    \n",
    "    # Invertir el escalado para las predicciones y los valores reales\n",
    "    test_predict_unscaled = []\n",
    "    y_test_unscaled = []\n",
    "    \n",
    "    for i in range(test_predict.shape[0]):\n",
    "        temp_predict = scaler.inverse_transform(np.concatenate([test_predict[i].reshape(-1, 1), np.tile(X_test[i, -1, 1:], (forecast_horizon, 1))], axis=1))[:, 0]\n",
    "        temp_y_test = scaler.inverse_transform(np.concatenate([y_test[i].reshape(-1, 1), np.tile(X_test[i, -1, 1:], (forecast_horizon, 1))], axis=1))[:, 0]\n",
    "        test_predict_unscaled.append(temp_predict)\n",
    "        y_test_unscaled.append(temp_y_test)\n",
    "    \n",
    "    test_predict_unscaled = np.array(test_predict_unscaled)\n",
    "    y_test_unscaled = np.array(y_test_unscaled)\n",
    "\n",
    "    return test_predict_unscaled\n",
    "\n",
    "def LogicaDifusa(P, N):\n",
    "    \n",
    "    # Antecedentes (precipitaciónn y nivel) y consecuente (Nivel o caudal)\n",
    "    PrecP = ctrl.Antecedent([P[EstP].min(), Percentiles[1][EstP].iloc[2, 0], Percentiles[1][EstP].iloc[1, 0], Percentiles[1][EstP].iloc[0, 0], P[EstP].max()], 'Precipitación Pasada')\n",
    "    PrecP2 = ctrl.Antecedent([P[EstP].min(), Percentiles[1][EstP].iloc[2, 0], Percentiles[1][EstP].iloc[1, 0], Percentiles[1][EstP].iloc[0, 0], P[EstP].max()], 'Precipitación Pasada2')\n",
    "    NivP = ctrl.Antecedent([N[EstN].min(), Percentiles[0][EstN].iloc[2,0], Percentiles[0][EstN].iloc[1,0], Percentiles[0][EstN].iloc[0, 0], N[EstN].max()], 'Nivel Pasado')\n",
    "    Niv = ctrl.Consequent([N[EstN].min(), Percentiles[0][EstN].iloc[2,0], Percentiles[0][EstN].iloc[1,0], Percentiles[0][EstN].iloc[0, 0], N[EstN].max()], 'Nivel')\n",
    "    \n",
    "    # Definición de membresí­as\n",
    "    PrecP['Bajo'] = fuzz.trimf(PrecP.universe, [P[EstP].min(), P[EstP].min(), Percentiles[1][EstP].iloc[2, 0]])\n",
    "    PrecP['Medio-Bajo'] = fuzz.trimf(PrecP.universe, [P[EstP].min(), Percentiles[1][EstP].iloc[2, 0], Percentiles[1][EstP].iloc[1, 0]])\n",
    "    PrecP['Medio'] = fuzz.trimf(PrecP.universe, [Percentiles[1][EstP].iloc[2, 0], Percentiles[1][EstP].iloc[1, 0], Percentiles[1][EstP].iloc[0, 0]])\n",
    "    PrecP['Alto'] = fuzz.trapmf(PrecP.universe, [Percentiles[1][EstP].iloc[1, 0], Percentiles[1][EstP].iloc[0, 0], P[EstP].max(), P[EstP].max()])\n",
    "\n",
    "    PrecP2['Bajo'] = fuzz.trimf(PrecP.universe, [P[EstP].min(), P[EstP].min(), Percentiles[1][EstP].iloc[2, 0]])\n",
    "    PrecP2['Medio-Bajo'] = fuzz.trimf(PrecP.universe, [P[EstP].min(), Percentiles[1][EstP].iloc[2, 0], Percentiles[1][EstP].iloc[1, 0]])\n",
    "    PrecP2['Medio'] = fuzz.trimf(PrecP.universe, [Percentiles[1][EstP].iloc[2, 0], Percentiles[1][EstP].iloc[1, 0], Percentiles[1][EstP].iloc[0, 0]])\n",
    "    PrecP2['Alto'] = fuzz.trapmf(PrecP.universe, [Percentiles[1][EstP].iloc[1, 0], Percentiles[1][EstP].iloc[0, 0], P[EstP].max(), P[EstP].max()])\n",
    "\n",
    "    NivP['Bajo'] = fuzz.trimf(Niv.universe, [N[EstN].min(), N[EstN].min(), Percentiles[0][EstN].iloc[2, 0]])\n",
    "    NivP['Medio-Bajo'] = fuzz.trimf(Niv.universe, [N[EstN].min(), Percentiles[0][EstN].iloc[2, 0], Percentiles[0][EstN].iloc[1, 0]])\n",
    "    NivP['Medio'] = fuzz.trimf(Niv.universe, [Percentiles[0][EstN].iloc[2, 0], Percentiles[0][EstN].iloc[1, 0], Percentiles[0][EstN].iloc[0, 0]])\n",
    "    NivP['Alto'] = fuzz.trapmf(Niv.universe, [Percentiles[0][EstN].iloc[1, 0], Percentiles[0][EstN].iloc[0, 0], N[EstN].max(), N[EstN].max()])\n",
    "    \n",
    "    Niv['Bajo (90-100%)'] = fuzz.trimf(Niv.universe, [N[EstN].min(), N[EstN].min(), Percentiles[0][EstN].iloc[2, 0]])\n",
    "    Niv['Medio-Bajo (50-90%)'] = fuzz.trimf(Niv.universe, [N[EstN].min(), Percentiles[0][EstN].iloc[2, 0], Percentiles[0][EstN].iloc[1, 0]])\n",
    "    Niv['Medio (10-50%)'] = fuzz.trimf(Niv.universe, [Percentiles[0][EstN].iloc[2, 0], Percentiles[0][EstN].iloc[1, 0], Percentiles[0][EstN].iloc[0, 0]])\n",
    "    Niv['Alto (0-10%)'] = fuzz.trapmf(Niv.universe, [Percentiles[0][EstN].iloc[1, 0], Percentiles[0][EstN].iloc[0, 0], N[EstN].max(), N[EstN].max()])\n",
    "\n",
    "    # REGLAS\n",
    "    B = ctrl.Rule(PrecP['Bajo'], Niv['Bajo (90-100%)'])\n",
    "    MB = ctrl.Rule(PrecP['Medio-Bajo'], Niv['Medio-Bajo (50-90%)'])\n",
    "    M = ctrl.Rule(PrecP['Medio'], Niv['Medio (10-50%)'])\n",
    "    A = ctrl.Rule(PrecP['Alto'], Niv['Alto (0-10%)'])\n",
    "\n",
    "    B2 = ctrl.Rule(PrecP2['Bajo'], Niv['Bajo (90-100%)'])\n",
    "    MB2 = ctrl.Rule(PrecP2['Medio-Bajo'], Niv['Medio-Bajo (50-90%)'])\n",
    "    M2 = ctrl.Rule(PrecP2['Medio'], Niv['Medio (10-50%)'])\n",
    "    A2 = ctrl.Rule(PrecP2['Alto'], Niv['Alto (0-10%)'])\n",
    "\n",
    "    Bn = ctrl.Rule(NivP['Bajo'], Niv['Bajo (90-100%)'])\n",
    "    MBn = ctrl.Rule(NivP['Medio-Bajo'], Niv['Medio-Bajo (50-90%)'])\n",
    "    Mn = ctrl.Rule(NivP['Medio'], Niv['Medio (10-50%)'])\n",
    "    An = ctrl.Rule(NivP['Alto'], Niv['Alto (0-10%)'])\n",
    "    \n",
    "    Pronosticos = pd.DataFrame(np.nan, index=DatosPrec[EstP].iloc[-dias_pasados:].index, columns=[f\"Día {i+1}\" for i in range(dias_futuros)], dtype=float)\n",
    "    N_Variables = int(input(\"¿Con qué variables desea trabajar?:\\n1. Precipitación t-1\\n2. Nivel t-1\\n3. Precipitación t-1, t-2\\n4. Precipitación t-1 y nivel t-1\\n5. Precipitación t-1, t-2 y nivel t-1\\n\"))\n",
    "    \n",
    "    if N_Variables == 1:\n",
    "        #Parametros para pdf\n",
    "        text = \"1_Variable_P(t-1)\"\n",
    "        estaciones = f'{EstP}'\n",
    "        REGLAS = \"precipitación t-1\"\n",
    "        # Parámetros para pronóstico\n",
    "        reglas = [B, MB, M, A]\n",
    "        def FL(i, dia):\n",
    "            Nivel.input['Precipitación Pasada'] = Prec_In.iloc[i, dia]\n",
    "            Nivel.compute()\n",
    "            Pronosticos.iloc[i, dia] = float(Nivel.output['Nivel'])\n",
    "            DATOS.iloc[i,0] = Prec_In.iloc[i, dia]\n",
    "            DATOS.iloc[i,3] = float(Nivel.output['Nivel'])\n",
    "        \n",
    "    if N_Variables == 2:\n",
    "        #Parametros para pdf\n",
    "        text = \"1_Variable_N(t-1)\"\n",
    "        estaciones = f'{EstN}'\n",
    "        REGLAS = \"nivel t-1\"\n",
    "        # Parámetros para pronóstico\n",
    "        reglas = [Bn, MBn, Mn, An]\n",
    "        def FL(i, dia):\n",
    "            Nivel.input['Nivel Pasado'] = Nivel_In.iloc[i, dia]\n",
    "            Nivel.compute()\n",
    "            Pronosticos.iloc[i, dia] = float(Nivel.output['Nivel'])\n",
    "            Nivel_In.iloc[i, dia + 1] = float(Nivel.output['Nivel'])\n",
    "            DATOS.iloc[i,2] = Nivel_In.iloc[i, dia]\n",
    "            DATOS.iloc[i,3] = float(Nivel.output['Nivel'])\n",
    "            \n",
    "    if N_Variables == 3:\n",
    "        #Parametros para pdf\n",
    "        text = \"2_Variables_P(t-1,t-2)\"\n",
    "        estaciones = f'{EstP}'\n",
    "        REGLAS = \"precipitación t-1 y t-2\"\n",
    "        # Parámetros para pronóstico\n",
    "        reglas = [B, MB, M, A, B2, MB2, M2, A2]\n",
    "        def FL(i, dia):\n",
    "            Nivel.input['Precipitación Pasada'] = Prec_In.iloc[i, dia]\n",
    "            Nivel.input['Precipitación Pasada2'] = Prec_In2.iloc[i, dia]\n",
    "            Nivel.compute()\n",
    "            Pronosticos.iloc[i, dia] = float(Nivel.output['Nivel'])\n",
    "            DATOS.iloc[i,0] = Prec_In.iloc[i, dia]\n",
    "            DATOS.iloc[i,1] = Prec_In2.iloc[i, dia]\n",
    "            DATOS.iloc[i,3] = float(Nivel.output['Nivel'])   \n",
    "        \n",
    "    if N_Variables == 4:\n",
    "        #Parametros para pdf\n",
    "        text = \"2_Variables_P(t-1)_N(t-1)\"\n",
    "        estaciones = f'{EstP}, {EstN}'\n",
    "        REGLAS = \"precipitación t-1 y nivel t-1\"\n",
    "        # Parámetros para pronóstico\n",
    "        reglas = [B, MB, M, A, Bn, MBn, Mn, An]\n",
    "        def FL(i, dia):\n",
    "            Nivel.input['Precipitación Pasada'] = Prec_In.iloc[i, dia]\n",
    "            Nivel.input['Nivel Pasado'] = Nivel_In.iloc[i, dia]\n",
    "            Nivel.compute()\n",
    "            Pronosticos.iloc[i, dia] = float(Nivel.output['Nivel'])\n",
    "            Nivel_In.iloc[i, dia + 1] = float(Nivel.output['Nivel'])\n",
    "            DATOS.iloc[i,0] = Prec_In.iloc[i, dia]\n",
    "            DATOS.iloc[i,2] = Nivel_In.iloc[i, dia]\n",
    "            DATOS.iloc[i,3] = float(Nivel.output['Nivel']) \n",
    "            \n",
    "    if N_Variables == 5:\n",
    "        #Parametros para pdf\n",
    "        text = \"3_Variables_P(t-1,t-2)_C(t-1)\"\n",
    "        estaciones = f'{EstP}, {EstN}'\n",
    "        REGLAS = \"precipitación t-1, t-2 y caudal t-1\"\n",
    "        # Parámetros para pronóstico\n",
    "        reglas = [B, MB, M, A, B2, MB2, M2, A2, Bn, MBn, Mn, An]\n",
    "        def FL(i, dia):\n",
    "            Nivel.input['Precipitación Pasada'] = Prec_In.iloc[i, dia]\n",
    "            Nivel.input['Precipitación Pasada2'] = Prec_In2.iloc[i, dia]\n",
    "            Nivel.input['Nivel Pasado'] = Nivel_In.iloc[i, dia]\n",
    "            Nivel.compute()\n",
    "            Pronosticos.iloc[i, dia] = float(Nivel.output['Nivel'])\n",
    "            Nivel_In.iloc[i, dia + 1] = float(Nivel.output['Nivel'])\n",
    "            DATOS.iloc[i,0] = Prec_In.iloc[i, dia]\n",
    "            DATOS.iloc[i,1] = Prec_In2.iloc[i, dia]\n",
    "            DATOS.iloc[i,2] = Nivel_In.iloc[i, dia]\n",
    "            DATOS.iloc[i,3] = float(Nivel.output['Nivel'])\n",
    "    \n",
    "    Nivel_ctrl = ctrl.ControlSystem(reglas)\n",
    "    Nivel = ctrl.ControlSystemSimulation(Nivel_ctrl)\n",
    "    \n",
    "    NR = pd.DataFrame(index=DatosPrec[EstP].iloc[-dias_pasados:].index, columns=range(dias_futuros))\n",
    "    PR = pd.DataFrame(index=DatosPrec[EstP].iloc[-dias_pasados:].index, columns=range(dias_futuros))\n",
    "\n",
    "    for i in range(dias_futuros):\n",
    "        NR.iloc[:dias_pasados-i,i] = N[EstN].iloc[-dias_pasados+i:].values\n",
    "        PR.iloc[:dias_pasados-i,i] = P[EstP].iloc[-dias_pasados+i:].values\n",
    "\n",
    "    NR = NR.astype(float)\n",
    "    PR = PR.astype(float)\n",
    "    \n",
    "    Prec_In = pd.DataFrame(index=P[EstP].iloc[-dias_pasados:].index, columns=range(dias_futuros))\n",
    "    Prec_In2 = pd.DataFrame(index=P[EstP].iloc[-dias_pasados-1:-1].index, columns=range(dias_futuros))\n",
    "    Nivel_In = pd.DataFrame(index=P[EstP].iloc[-dias_pasados:].index, columns=range(dias_futuros + 1))\n",
    "    \n",
    "    # Asignar valores de t-1 y t-2 (reales)\n",
    "    Prec_In[0] = P[EstP].iloc[-dias_pasados:].values.flatten()  \n",
    "    Prec_In2[0] = P[EstP].iloc[-dias_pasados-1:-1].values.flatten()\n",
    "    Prec_In2[1] = P[EstP].iloc[-dias_pasados:].values.flatten()\n",
    "    Nivel_In[0] = DatosNiv[EstN].iloc[-dias_pasados:].values.flatten() \n",
    "    \n",
    "    # Asignar predicciones a las columnas restantes\n",
    "    for i in range(dias_pasados):\n",
    "        Prec_In.iloc[i, 1:] = test_predict_unscaled[-dias_pasados+i, :]\n",
    "        Prec_In2.iloc[i, 2:] = test_predict_unscaled[-dias_pasados-1+i, 1:]\n",
    "    \n",
    "    DATOS = pd.DataFrame(index=P[EstP].iloc[-dias_pasados:].index, columns=['Prec_t-1', 'Prec_t-2', 'Niv_t-1', 'Pronostico'])\n",
    "    \n",
    "    for i in range(dias_pasados):\n",
    "        \n",
    "        a = dias_pasados - i\n",
    "        \n",
    "        for dia in range(dias_futuros):\n",
    "            \n",
    "            FL(i, dia)\n",
    "        \n",
    "    # Calcular las métricas RMSE, MAE y R²\n",
    "    metrics = {'RMSE': [], 'MAE': [], 'R²': [], 'NSlog': [], 'PBIAS': [], 'MAPE': [], 'RMSPE': []}\n",
    "\n",
    "    for day in range(dias_futuros):\n",
    "\n",
    "        a = dias_pasados - day\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(NR.iloc[:a, day], Pronosticos.iloc[:a, day]))\n",
    "        mae = mean_absolute_error(NR.iloc[:a, day], Pronosticos.iloc[:a, day])\n",
    "        r2 = r2_score(NR.iloc[:a, day], Pronosticos.iloc[:a, day])\n",
    "        nr_log = np.log(NR.iloc[:a, day] + 1)\n",
    "        pred_log = np.log(Pronosticos.iloc[:a, day] + 1)\n",
    "        nslog = 1 - (np.sum((nr_log - pred_log) ** 2) / np.sum((nr_log - np.mean(nr_log)) ** 2))\n",
    "        pbias = 100 * (np.sum(NR.iloc[:a, day] - Pronosticos.iloc[:a, day]) / np.sum(NR.iloc[:a, day]))\n",
    "        mape = 100 * np.mean(np.abs((NR.iloc[:a, day] - Pronosticos.iloc[:a, day]) / NR.iloc[:a, day]))\n",
    "        rmspe = 100 * np.sqrt(np.mean(((NR.iloc[:a, day] - Pronosticos.iloc[:a, day]) / NR.iloc[:a, day]) ** 2))\n",
    "        metrics['RMSE'].append(rmse)\n",
    "        metrics['MAE'].append(mae)\n",
    "        metrics['R²'].append(r2)\n",
    "        metrics['NSlog'].append(nslog)\n",
    "        metrics['PBIAS'].append(pbias)\n",
    "        metrics['MAPE'].append(mape)\n",
    "        metrics['RMSPE'].append(rmspe)\n",
    "        \n",
    "        print(f\"Día {day + 1} - RMSE: {rmse}, MAE: {mae}, R²: {r2}, NSlog: {nslog}, PBIAS: {pbias}, MAPE: {mape}, RMSPE: {rmspe}\")\n",
    "    \n",
    "    return NR, PR, Pronosticos, PrecP, Niv, metrics, DATOS, estaciones, REGLAS\n",
    "    \n",
    "def confianza2():\n",
    "    # Definir los percentiles del eje X\n",
    "    percentiles_x = [2.5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 97.5]\n",
    "    percentiles_labels = ['P2.5', 'P10', 'P20', 'P30', 'P40', 'P50', 'P60', 'P70', 'P80', 'P90', 'P97.5']\n",
    "\n",
    "    # Obtener percentiles reales\n",
    "    real = NR.iloc[-len(Pronosticos):,0]\n",
    "    percentilesR = np.percentile(real, percentiles_x)\n",
    "\n",
    "    # Crear DataFrames para cada día y calcular percentiles y rangos en bucle\n",
    "    dias_percentiles = {}\n",
    "    for dia in range(1, dias_futuros+1):\n",
    "        # Ordenar los valores pronosticados\n",
    "        ordenados = Pronosticos.iloc[:, dia - 1].dropna().sort_values(ascending=True).reset_index(drop=True)\n",
    "\n",
    "        # Crear un DataFrame para cada día\n",
    "        dia_df = pd.DataFrame({'Nombre': percentiles_labels})\n",
    "\n",
    "        # Calcular los percentiles\n",
    "        dia_df['percentiles'] = [np.percentile(ordenados, i) for i in percentiles_x]\n",
    "\n",
    "        # Función para calcular los rangos C10, C90, C5, C95\n",
    "        def calcular_rang(ordenados, percentil, percentiles_x):\n",
    "            # Obtener el percentil anterior\n",
    "            if percentil == percentiles_x[0]:\n",
    "                p_anterior = 0\n",
    "            else:\n",
    "                p_anterior = np.percentile(ordenados, percentiles_x[percentiles_x.index(percentil) - 1])\n",
    "\n",
    "            # Filtrar los datos que están en la marca de clase\n",
    "            p = ordenados[(ordenados <= np.percentile(ordenados, percentil)) & (ordenados > p_anterior)]\n",
    "\n",
    "            # Calcular los percentiles\n",
    "            c10 = np.percentile(p, 10) if len(p) > 0 else np.nan  # Verificar longitud para evitar errores\n",
    "            c90 = np.percentile(p, 90) if len(p) > 0 else np.nan\n",
    "            c5 = np.percentile(p, 5) if len(p) > 0 else np.nan\n",
    "            c95 = np.percentile(p, 95) if len(p) > 0 else np.nan\n",
    "            return c10, c90, c5, c95\n",
    "\n",
    "        # Calcular los rangos para cada percentil y agregar al DataFrame\n",
    "        dia_df[['C10', 'C90', 'C5', 'C95']] = [calcular_rang(ordenados, i, percentiles_x) for i in percentiles_x]\n",
    "\n",
    "        # Guardar el DataFrame del día en el diccionario\n",
    "        dias_percentiles[f'Dia_{dia}'] = dia_df\n",
    "\n",
    "    return dias_percentiles, percentilesR\n",
    "\n",
    "def excel():\n",
    "    \n",
    "    # Especifica la ruta y el nombre del archivo\n",
    "    ruta_archivo = f'Series{Resample}Días_Estación{EstN}.xlsx'\n",
    "\n",
    "    Series = pd.DataFrame(index=DatosPrec[EstP].iloc[-dias_pasados:].index, columns=['Caudal medio real [m3/s]', 'Precipitación real acumulada [mm]'])\n",
    "    \n",
    "    Series.iloc[:,0] = NR.iloc[:,0]\n",
    "    Series.iloc[:,1] = PR.iloc[:,0]\n",
    "    \n",
    "    # Crea un archivo Excel y guarda cada DataFrame en una hoja diferente\n",
    "    with pd.ExcelWriter(ruta_archivo, engine='openpyxl') as writer:\n",
    "        Series.to_excel(writer, sheet_name='Series', index=False)\n",
    "        Pronosticos.to_excel(writer, sheet_name='Pronosticos', index=False)\n",
    "        DATOS.to_excel(writer, sheet_name='Datos', index=False)\n",
    "    \n",
    "    print(f\"Archivo Excel guardado en {ruta_archivo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8b37be5b-be07-46d0-a694-cb2419b24b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo seleccionado: C:/Users/juanj/Downloads/Estaciones/Estaciones/H5025/Seleccionado/Niveles_H5025_relleno.csv\n",
      "Archivo seleccionado: C:/Users/juanj/Downloads/Estaciones/Estaciones/H5025/Seleccionado/Niveles_H5025_relleno.csv\n",
      "Has seleccionado la estación: 5025\n",
      "Archivo seleccionado: C:/Users/juanj/Downloads/Estaciones/Estaciones/H5025/Seleccionado/Prec_H5025_relleno.csv\n",
      "Has seleccionado la estación: P39\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ingrese el número de resampleo:  7\n",
      "Ingrese el número de días futuros:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "27/27 - 9s - loss: 0.1530 - val_loss: 0.1813 - 9s/epoch - 333ms/step\n",
      "Epoch 2/20\n",
      "27/27 - 0s - loss: 0.1483 - val_loss: 0.1661 - 403ms/epoch - 15ms/step\n",
      "Epoch 3/20\n",
      "27/27 - 0s - loss: 0.1454 - val_loss: 0.1648 - 366ms/epoch - 14ms/step\n",
      "Epoch 4/20\n",
      "27/27 - 0s - loss: 0.1453 - val_loss: 0.1646 - 426ms/epoch - 16ms/step\n",
      "Epoch 5/20\n",
      "27/27 - 0s - loss: 0.1439 - val_loss: 0.1641 - 392ms/epoch - 15ms/step\n",
      "Epoch 6/20\n",
      "27/27 - 0s - loss: 0.1445 - val_loss: 0.1648 - 356ms/epoch - 13ms/step\n",
      "Epoch 7/20\n",
      "27/27 - 0s - loss: 0.1440 - val_loss: 0.1642 - 371ms/epoch - 14ms/step\n",
      "Epoch 8/20\n",
      "27/27 - 0s - loss: 0.1429 - val_loss: 0.1653 - 366ms/epoch - 14ms/step\n",
      "Epoch 9/20\n",
      "27/27 - 0s - loss: 0.1422 - val_loss: 0.1673 - 355ms/epoch - 13ms/step\n",
      "Epoch 10/20\n",
      "27/27 - 0s - loss: 0.1434 - val_loss: 0.1640 - 348ms/epoch - 13ms/step\n",
      "Epoch 11/20\n",
      "27/27 - 0s - loss: 0.1443 - val_loss: 0.1649 - 349ms/epoch - 13ms/step\n",
      "Epoch 12/20\n",
      "27/27 - 0s - loss: 0.1412 - val_loss: 0.1733 - 355ms/epoch - 13ms/step\n",
      "Epoch 13/20\n",
      "27/27 - 0s - loss: 0.1425 - val_loss: 0.1654 - 347ms/epoch - 13ms/step\n",
      "Epoch 14/20\n",
      "27/27 - 0s - loss: 0.1397 - val_loss: 0.1719 - 333ms/epoch - 12ms/step\n",
      "Epoch 15/20\n",
      "27/27 - 0s - loss: 0.1407 - val_loss: 0.1639 - 331ms/epoch - 12ms/step\n",
      "Epoch 16/20\n",
      "27/27 - 0s - loss: 0.1409 - val_loss: 0.1670 - 339ms/epoch - 13ms/step\n",
      "Epoch 17/20\n",
      "27/27 - 0s - loss: 0.1391 - val_loss: 0.1660 - 438ms/epoch - 16ms/step\n",
      "Epoch 18/20\n",
      "27/27 - 0s - loss: 0.1383 - val_loss: 0.1718 - 387ms/epoch - 14ms/step\n",
      "Epoch 19/20\n",
      "27/27 - 0s - loss: 0.1389 - val_loss: 0.1656 - 377ms/epoch - 14ms/step\n",
      "Epoch 20/20\n",
      "27/27 - 0s - loss: 0.1412 - val_loss: 0.1736 - 356ms/epoch - 13ms/step\n",
      "5/5 [==============================] - 2s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "Datos_Historicos_Nivel = LeerArchivos(\"datos historicos de nivel\")\n",
    "DatosNiv = LeerArchivos(\"periodo seleccionado de nivel\")\n",
    "EstN = ElegirEstacion(DatosNiv, \"nivel\")\n",
    "DatosPrec = LeerArchivos(\"periodo seleccionado de precipitacion\")\n",
    "EstP = ElegirEstacion(DatosPrec, \"precipitación\")\n",
    "DatosNiv, DatosPrec, Resample = resample(DatosNiv, DatosPrec)\n",
    "\n",
    "dias_futuros = int(input(\"Ingrese el número de días futuros: \"))\n",
    "\n",
    "test_predict_unscaled = ANN()\n",
    "dias_pasados = len(test_predict_unscaled) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0b662469-7316-4746-a512-29ab8391a1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "¿Con qué variables desea trabajar?:\n",
      "1. Precipitación t-1\n",
      "2. Nivel t-1\n",
      "3. Precipitación t-1, t-2\n",
      "4. Precipitación t-1 y nivel t-1\n",
      "5. Precipitación t-1, t-2 y nivel t-1\n",
      " 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Día 1 - RMSE: 0.02365050484848759, MAE: 0.01656758327299536, R²: 0.8792538232380742, NSlog: 0.8860030176489175, PBIAS: -1.5844157714551725, MAPE: 4.724164799818205, RMSPE: 6.404194043981315\n",
      "Día 2 - RMSE: 0.07634721543402821, MAE: 0.05763991648176452, R²: -0.36206838731715485, NSlog: -0.33167379713459666, PBIAS: -3.849589137651387, MAPE: 17.16065471543078, RMSPE: 22.54796499627992\n"
     ]
    }
   ],
   "source": [
    "Percentiles = []\n",
    "Percentiles, rangos = CDG(DatosNiv, 10, 50, 90, 0)  \n",
    "Percentiles, rangos = CDG(DatosPrec, 0, 1, 2, 1)\n",
    "\n",
    "NR, PR, Pronosticos, PrecP, Niv, metrics, DATOS, estaciones, REGLAS = LogicaDifusa(DatosPrec, DatosNiv)\n",
    "dias_percentiles, percentilesR = confianza2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "43d45634-6b65-4374-9d81-8155726f46ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados y gráficos guardados en el archivo Series7Días_Estación5025.pdf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juanj\\.conda\\envs\\Scikit-fuzzi\\lib\\site-packages\\matplotlib\\figure.py:456: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  warnings.warn(\n",
      "C:\\Users\\juanj\\.conda\\envs\\Scikit-fuzzi\\lib\\site-packages\\matplotlib\\figure.py:456: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Generar excel\n",
    "#excel()\n",
    "\n",
    "# Generar nombre del archivo PDF dinámico basado en variables y nombres de las columnas\n",
    "pdf_filename = f'Series{Resample}Días_Estación{EstN}.pdf'\n",
    "\n",
    "# Crear el archivo PDF para guardar gráficos y métricas\n",
    "with PdfPages(pdf_filename) as pdf:\n",
    "    # Página 1: Información general\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.text(0.5, 0.9, 'Variables Utilizadas en el Pronóstico:', ha='center', fontsize=14)\n",
    "    plt.text(0.5, 0.8, f'{estaciones}', ha='center', fontsize=12)\n",
    "    plt.text(0.5, 0.7, f'Variable Pronosticada: Caudal en estación {EstN}', ha='center', fontsize=14)\n",
    "    plt.text(0.5, 0.6, f'Reglas basadas en {REGLAS}', ha='center', fontsize=14)\n",
    "    plt.text(0.5, 0.5, f'Rangos de: Caudal{rangos.iloc[0,0]}, Precipitación{rangos.iloc[1,0]}', ha='center', fontsize=12)\n",
    "    plt.text(0.5, 0.4, 'Métricas de Ajuste:', ha='center', fontsize=14)\n",
    "    for i in range(dias_futuros):\n",
    "        plt.text(0.5, 0.3 - i*0.05, f\"Día {i + 1} - RMSE: {metrics['RMSE'][i]:.4f}, MAE: {metrics['MAE'][i]:.4f}, R²: {metrics['R²'][i]:.4f}, NSlog: {metrics['NSlog'][i]:.4f}, PBIAS: {metrics['PBIAS'][i]:.4f}, MAPE: {metrics['MAPE'][i]:.4f}%, RMSPE: {metrics['RMSPE'][i]:.4f}\",\n",
    "                 ha='center', fontsize=11)\n",
    "    plt.axis('off')\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "    \n",
    "    # Gráficos de predicción e intervalos de confianza\n",
    "    for day in range(dias_futuros):\n",
    "\n",
    "        a = dias_pasados - day\n",
    "        Dia = dias_percentiles[f'Dia_{day+1}']\n",
    "\n",
    "        # Crear subplots: 1 fila y 2 columnas\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "        # Gráfico 1: Pronóstico vs Realidad\n",
    "        ax1.set_title(f'Pronóstico del Día {day+1}')\n",
    "        ax1.plot(DatosPrec.index[-len(NR):], NR.iloc[:, 0], label= 'Caudal Real')\n",
    "        ax1.plot(DatosPrec.index[-len(NR):], Pronosticos.iloc[:, day], label= 'Pronóstico', color='red')\n",
    "        ax1.set_xlabel('Fecha')\n",
    "        ax1.set_ylabel('Caudal (m3/s)')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "\n",
    "        # Gráfico 2: Intervalos de confianza\n",
    "        ax2.set_title(f'Día {day+1} - Intervalo de Confianza')\n",
    "        ax2.plot(Dia['Nombre'], percentilesR, label='Caudal real', color='black', linewidth=1.5)\n",
    "\n",
    "        # Graficar los intervalos de confianza\n",
    "        ax2.fill_between(Dia['Nombre'], Dia['C10'], Dia['C90'], color='blue', alpha=0.2, label='C10-C90')\n",
    "        ax2.fill_between(Dia['Nombre'], Dia['C5'], Dia['C95'], color='gray', alpha=0.2, label='C5-C95')\n",
    "\n",
    "        ax2.set_xlabel('Percentil')\n",
    "        ax2.set_ylabel('Caudal (m3/s)')\n",
    "        ax2.legend(loc='upper left')\n",
    "        ax2.grid(True)\n",
    "\n",
    "        # Ajustar el espaciado entre los subplots\n",
    "        plt.tight_layout()\n",
    "\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "        \n",
    "    # Gráfico de MAE, RMSE, R²\n",
    "    days = range(1, dias_futuros + 1)\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "    # Gráfico de RMSE y MAE en el eje primario\n",
    "    ax1.plot(days, metrics['RMSE'], label='RMSE', color='b')\n",
    "    ax1.plot(days, metrics['MAE'], label='MAE', color='g')\n",
    "    ax1.set_xlabel('Día de Pronóstico')\n",
    "    ax1.set_ylabel('RMSE / MAE', color='black')\n",
    "    ax1.tick_params(axis='y', labelcolor='black')\n",
    "    ax1.grid(True)\n",
    "    # Crear el segundo eje (eje secundario) para R²\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(days, metrics['R²'], label='R²', color='r')\n",
    "    ax2.set_ylabel('R²', color='black')\n",
    "    ax2.tick_params(axis='y', labelcolor='black')\n",
    "    # Añadir leyendas para cada eje\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    # Título de la gráfica\n",
    "    plt.title('Métricas de Pronóstico para Cada Día')\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # Gráfico de NSlog, RMSPE, MAPE\n",
    "    days = range(1, dias_futuros + 1)\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "    # Gráfico de RMSPE y MAPE en el eje primario\n",
    "    ax1.plot(days, metrics['RMSPE'], label='RMPSE', color='b')\n",
    "    ax1.plot(days, metrics['MAPE'], label='MAPE', color='g')\n",
    "    ax1.set_xlabel('Día de Pronóstico')\n",
    "    ax1.set_ylabel('RMSPE / MAPE', color='black')\n",
    "    ax1.tick_params(axis='y', labelcolor='black')\n",
    "    ax1.grid(True)\n",
    "    # Crear el segundo eje (eje secundario) para R²\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(days, metrics['NSlog'], label='NSlog', color='r')\n",
    "    ax2.set_ylabel('NSlog', color='black')\n",
    "    ax2.tick_params(axis='y', labelcolor='black')\n",
    "    # Añadir leyendas para cada eje\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    # Título de la gráfica\n",
    "    plt.title('Métricas de Pronóstico para Cada Día')\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # Gráfico de PBIAS\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    days = range(1, dias_futuros + 1)\n",
    "    plt.plot(days, metrics['PBIAS'], label='PBIAS')\n",
    "    plt.title('Métricas de Pronóstico para Cada Día')\n",
    "    plt.xlabel('Día de Pronóstico')\n",
    "    plt.ylabel('Métrica')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "    \n",
    "    # Gráfico membresías de precipitación y nivel\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    Niv.view()\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    PrecP.view()\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "    \n",
    "# Mensaje de finalización\n",
    "print(f\"Resultados y gráficos guardados en el archivo {pdf_filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2a741e-e94c-4d23-89e8-f6591f97b0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
